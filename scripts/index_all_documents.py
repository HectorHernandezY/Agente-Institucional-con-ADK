"""
Script para indexar documentos UNO POR UNO (streaming mode)
Minimiza uso de RAM procesando y liberando memoria inmediatamente
"""
import os
import sys
import gc
import time

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from google.cloud import storage
from google.auth import default

# Configuraci√≥n
PROJECT_ID = os.getenv("FIRESTORE_PROJECT_ID", "muruna-utem-project")
GCS_BUCKET = os.getenv("GCS_RAG_BUCKET", "db_agent_utem")


def get_file_iterator(folder_path: str = "files_utem/"):
    """
    Generador que retorna archivos UNO a la vez (no carga la lista completa)
    """
    credentials, _ = default(quota_project_id=PROJECT_ID)
    storage_client = storage.Client(project=PROJECT_ID, credentials=credentials)
    
    bucket = storage_client.bucket(GCS_BUCKET)
    
    # Usar iterator en lugar de list() - NO carga todo en memoria
    for blob in bucket.list_blobs(prefix=folder_path):
        if not blob.name.endswith('/'):  # Ignorar carpetas
            yield blob.name


def count_files(folder_path: str = "files_utem/") -> int:
    """Cuenta archivos sin cargarlos en memoria"""
    count = 0
    for _ in get_file_iterator(folder_path):
        count += 1
    return count


def main():
    print("Iniciando indexaci√≥n de documentos (modo streaming)")
    print("=" * 70)
    
    # Contar archivos primero
    print("\nüîç Contando archivos en GCS...")
    try:
        total_files = count_files(folder_path="files_utem/")
    except Exception as e:
        print(f"‚ùå Error al acceder a GCS: {e}")
        return
    
    if total_files == 0:
        print("‚ö†Ô∏è  No se encontraron archivos para indexar")
        return
    
    print(f"üìÅ Se procesar√°n {total_files} archivos\n")
    
    # Importar la funci√≥n SOLO cuando se necesite
    from my_agent_utem.tools.index_documents import index_document_from_gcs
    
    # Contadores
    success_count = 0
    error_count = 0
    errors_list = []
    success_list = []
    
    # Procesar archivo por archivo usando el generador
    for idx, file_path in enumerate(get_file_iterator("files_utem/"), 1):
        print("=" * 70)
        print(f"[{idx}/{total_files}] Procesando: {file_path}")
        print("-" * 70)
        
        try:
            # Indexar documento (esto hace las llamadas a GCP)
            result = index_document_from_gcs(file_path)
            
            if result["ok"]:
                success_count += 1
                chunks = result.get('chunks_created', 0)
                print(f"‚úÖ √âxito - {chunks} chunks creados")
                success_list.append((file_path, chunks))
            else:
                error_count += 1
                error_msg = result.get('message', 'Unknown error')
                print(f"‚ùå Error: {error_msg}")
                errors_list.append((file_path, error_msg))
            
        except KeyboardInterrupt:
            print("\n\n‚ö†Ô∏è  Indexaci√≥n interrumpida por el usuario")
            break
            
        except Exception as e:
            error_count += 1
            error_msg = str(e)
            print(f"‚ùå Excepci√≥n: {error_msg}")
            errors_list.append((file_path, error_msg))
        
        # CR√çTICO: Forzar liberaci√≥n de memoria
        gc.collect()
        
        # Pausa para evitar rate limiting de APIs
        if idx < total_files:
            time.sleep(0.5)
        
        print()
    
    # Resumen final
    print("=" * 70)
    print("üìä RESUMEN FINAL")
    print("=" * 70)
    processed = success_count + error_count
    print(f"Total archivos procesados: {processed}/{total_files}")
    print(f"‚úÖ Exitosos: {success_count}")
    print(f"‚ùå Errores: {error_count}")
    
    if processed > 0:
        print(f"üìà Tasa de √©xito: {(success_count/processed*100):.1f}%")
    
    # Detalles de errores
    if errors_list:
        print(f"\n‚ùå ARCHIVOS CON ERRORES ({len(errors_list)}):")
        print("-" * 70)
        for file_path, error_msg in errors_list:
            print(f"  ‚Ä¢ {os.path.basename(file_path)}")
            print(f"    ‚Üí {error_msg[:100]}...")
    
    # Detalles de √©xitos
    if success_list:
        print(f"\n‚úÖ ARCHIVOS INDEXADOS ({len(success_list)}):")
        print("-" * 70)
        total_chunks = 0
        for file_path, chunks in success_list:
            print(f"  ‚Ä¢ {os.path.basename(file_path)} ({chunks} chunks)")
            total_chunks += chunks
        print(f"\n  üì¶ Total de chunks creados: {total_chunks}")
    
    print("\n" + "=" * 70)
    print("üéâ Indexaci√≥n completada")
    print("=" * 70)


if __name__ == "__main__":
    main()